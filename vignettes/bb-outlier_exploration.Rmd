---
title: "Valeurs numériques anormales"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{bb-outlier_exploration}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, message=FALSE}
library(evavelo)
library(dplyr)
options(tibble.print_min = 20)
```

```{r}
#path <- here::here("../Data/01_Link_removed.xlsx")
# eva_data <- evavelo::read_evavelo(path)
# saveRDS(eva_data, "full_data.Rds")

## Loading example data
# eva_data <- evavelo:::evavelo_example
enquete <- readRDS("../full_data.Rds")$enquete %>% 
  as_tibble()
  

```
Eva-Scan:
Document de travail sur la détection d'anomalies pour différentes valeurs numériques.

Analyse d'un fichier type '01_full_data.xlsx'

## km_sortie (3.1.14)

L'idee est de sortir le premier et le dernier centile pour qu'ils puissent être analysés.
Le regroupement se fait par catégorie de cyclistes.

Je rajoute une méthode classique de 1.5 x intervalle interquantile car il est demandé de comparer par rapport à la médiane dans la méthodologie:

```{r}

## Attention, penser à utiliser categorie_corrige dans le traitement réel
data_km <- enquete %>% 
  select(id_quest, km_sortie, 
         categorie) %>% 
  filter(!is.na(km_sortie))

# Verification de quantiles
data_km %>% 
  group_by(categorie) %>% 
  summarize(
    p01 = quantile(km_sortie, 0.01),
    p10 = quantile(km_sortie, 0.1),
    p25 = quantile(km_sortie, 0.25),
    P75 = quantile(km_sortie, 0.75),
    p90 = quantile(km_sortie, 0.9),
    p99 = quantile(km_sortie, 0.99),
    med = median(km_sortie),
    n = n() )

## First approach with percentile
### First centile
data_km %>% 
  group_by(categorie) %>% 
  filter(km_sortie < quantile(km_sortie, 0.01))
### Last centile
data_km %>% 
  group_by(categorie) %>% 
  filter(km_sortie > quantile(km_sortie, 0.99))

## IQR approach
data_km %>% 
  group_by(categorie) %>% 
  filter(km_sortie < quantile(km_sortie, 0.25) - 1.5 * IQR(km_sortie) |
           km_sortie > quantile(km_sortie, 0.75) + 1.5 * IQR(km_sortie))


```

## dms  (3.1.17)

Meme type d'approche avec la detection du permier et dernier decile. 
TODO: Le regroupement doit se faire par mode_heb_regroupe. Si jamais un groupe est > 200 réponses, on peut le subdiviser ensuite en categorie_corrige.

Il faudra aussi détecter les valeurs <1 et ==365



### Regroupement par categorie

```{r}
data_dms <- enquete %>% 
  select(id_quest, dms, 
         categorie, mode_heb_regroupe, mode_heb_regroupe2) %>% 
  filter(!is.na(dms)) %>% 
  group_by(categorie)

# Verification de quantiles
data_dms %>% 
  summarize(
    p01 = quantile(dms, 0.01),
    p10 = quantile(dms, 0.1),
    p25 = quantile(dms, 0.25),
    P75 = quantile(dms, 0.75),
    p90 = quantile(dms, 0.9),
    p99 = quantile(dms, 0.99),
    med = median(dms),
    n = n() )

## Grouping by category
### First approach with percentile
data_dms %>% 
  filter(dms < quantile(dms, 0.01))

data_dms %>% 
  filter(dms > quantile(dms, 0.99))

### IQR approach
data_dms %>% 
  filter(dms < quantile(dms, 0.25) - 1.5 * IQR(dms) |
           dms > quantile(dms, 0.75) + 1.5 * IQR(dms))
```
### Regroupement par categorie et mode_heb_regroupe
 Mon échantillon ne semble pas assez important pour pouvoir faire une détection correcte par categorie et mode_heb_regroupe:
 
```{r}
## Grouping by category AND mode_heb_regroupe
data_dms_heb <- data_dms %>% 
  group_by(categorie, mode_heb_regroupe)

# Verification de quantiles
data_dms_heb %>% 
  summarize(
    p01 = quantile(dms, 0.01),
    p10 = quantile(dms, 0.1),
    p25 = quantile(dms, 0.25),
    P75 = quantile(dms, 0.75),
    p90 = quantile(dms, 0.9),
    p99 = quantile(dms, 0.99),
    med = median(dms),
    n = n() )

### First approach with percentile
data_dms_heb %>% 
  filter(dms < quantile(dms, 0.01))

data_dms_heb %>% 
  filter(dms > quantile(dms, 0.99))

### IQR approach
data_dms_heb %>% 
  filter(dms < quantile(dms, 0.25) - 1.5 * IQR(dms) |
           dms > quantile(dms, 0.75) + 1.5 * IQR(dms))


```
### Regroupement par mode_heb_regroupe


 
```{r}
## Grouping by mode_heb_regroupe
data_dms_heb <- data_dms %>% 
  group_by(mode_heb_regroupe)

# Verification de quantiles
data_dms_heb %>% 
  summarize(
    p01 = quantile(dms, 0.01),
    p10 = quantile(dms, 0.1),
    p25 = quantile(dms, 0.25),
    P75 = quantile(dms, 0.75),
    p90 = quantile(dms, 0.9),
    p99 = quantile(dms, 0.99),
    med = median(dms),
    n = n() )

### First approach with percentile
data_dms_heb %>% 
  filter(dms < quantile(dms, 0.01))

data_dms_heb %>% 
  filter(dms > quantile(dms, 0.99))

### IQR approach
data_dms_heb %>% 
  filter(dms < quantile(dms, 0.25) - 1.5 * IQR(dms) |
           dms > quantile(dms, 0.75) + 1.5 * IQR(dms))


```

##  revenu (3.1.33)

Signaler les premier et dernier decile de revenu

```{r}
data_revenu <- enquete %>% 
  select(id_quest, revenu) %>% 
  filter(!is.na(revenu))

data_revenu %>% 
  summarize(
    p01 = quantile(revenu, 0.01),
    p10 = quantile(revenu, 0.1),
    p25 = quantile(revenu, 0.25),
    P75 = quantile(revenu, 0.75),
    p90 = quantile(revenu, 0.9),
    p99 = quantile(revenu, 0.99),
    med = median(revenu),
    n = n() )


## First approach with percentile
data_revenu %>% 
  filter(revenu < quantile(revenu, 0.01))

data_revenu %>% 
  filter(revenu > quantile(revenu, 0.99))

## IQR approach
data_revenu %>% 
  filter(revenu < quantile(revenu, 0.25) - 1.5 * IQR(revenu) |
           revenu > quantile(revenu, 0.75) + 1.5 * IQR(revenu))
```

## depense [tour_dep_xxx] (3.1.26)

Mon fichier d'exemple ne comporte que des coûts de type [tour_dep_heb] mais le code ci-dessous fonctionne avec plusieurs type de dépenses 

TODO: grouper par categorie sauf pour transport et hebergement

```{r}
data_depense <- enquete %>% 
  select(id_quest, 
         starts_with("tour_dep_"),
         - ends_with("corrige"),
         - ends_with("valide")) %>% 
  tidyr::pivot_longer(starts_with("tour_dep"),
                      names_to = "depense",
                      values_to = "valeur") %>% 
  filter(!is.na(valeur)) %>% 
  group_by(depense)

data_depense %>% 
  group_by(depense) %>% 
  summarize(
    p01 = quantile(valeur, 0.01),
    p10 = quantile(valeur, 0.1),
    p25 = quantile(valeur, 0.25),
    P75 = quantile(valeur, 0.75),
    p90 = quantile(valeur, 0.9),
    p99 = quantile(valeur, 0.99),
    med = median(valeur),
    n = n() )

## First approach with percentile
data_depense %>% 
  filter(valeur < quantile(valeur, 0.01))

data_depense %>% 
  filter(valeur > quantile(valeur, 0.99))

## IQR approach
data_depense %>% 
  filter(valeur < quantile(valeur, 0.25) - 1.5 * IQR(valeur) |
           valeur > quantile(valeur, 0.75) + 1.5 * IQR(valeur))
```


