---
title: "Valeurs numériques anormales"
output: 
  html_document:
    toc: true
    toc_float: true
vignette: >
  %\VignetteIndexEntry{bb-outlier_exploration}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, message=FALSE}
library(evavelo)
library(dplyr)
options(tibble.print_min = 20)
options(dplyr.summarise.inform = FALSE)
```

```{r}
# path <- here::here("../Data/01_Link_removed.xlsx")
# eva_data <- evavelo::read_evavelo(path)
# saveRDS(eva_data, "full_data.Rds")

## Loading example data
# eva_data <- evavelo:::evavelo_example
enquete <- readRDS("full_data.Rds")$enquete %>% 
  as_tibble() %>% 
  mutate(categorie_corrige_corrige = categorie) ## to simulate corrected categorie_corrige
  

```

Eva-Scan: Document de travail sur la détection d'anomalies pour différentes valeurs numériques.

Analyse d'un fichier type **'01_full_data.xlsx'**

## km_sortie (3.1.14)

```{r}

## Data selection
data_km <- enquete %>% 
  select(id_quest, km_sortie, 
         categorie_corrige) %>% 
  filter(!is.na(km_sortie))

# quantile check
data_km %>% 
  group_by(categorie_corrige) %>% 
  summarize(
    p01 = quantile(km_sortie, 0.01),
    p10 = quantile(km_sortie, 0.1),
    p25 = quantile(km_sortie, 0.25),
    P75 = quantile(km_sortie, 0.75),
    p90 = quantile(km_sortie, 0.9),
    p99 = quantile(km_sortie, 0.99),
    med = median(km_sortie),
    n = n() )
```

L'idee est de sortir le premier et le dernier centile pour qu'ils puissent être analysés. Le regroupement se fait par catégorie de cyclistes.

Je rajoute une méthode classique de 1.5 x intervalle interquantile car il est demandé de comparer par rapport à la médiane dans la méthodologie:

```{r}
## First approach with percentile
### First centile
data_km %>% 
  group_by(categorie_corrige) %>% 
  filter(km_sortie < quantile(km_sortie, 0.01))
### Last centile
data_km %>% 
  group_by(categorie_corrige) %>% 
  filter(km_sortie > quantile(km_sortie, 0.99))

## IQR approach
data_km %>% 
  group_by(categorie_corrige) %>% 
  filter(km_sortie < quantile(km_sortie, 0.25) - 1.5 * IQR(km_sortie) |
           km_sortie > quantile(km_sortie, 0.75) + 1.5 * IQR(km_sortie))

```

## dms (3.1.17)

Meme type d'approche avec la detection du permier et dernier decile.

La différence maeure concerne le mode regroupement. Le regroupement se fait par mode_heb_regroupe. Si jamais un groupe est \> 200 réponses, on le subdivise ensuite en categorie_corrige_corrige (et on regroupe ensemble les catégories avec moins de 50 réponses) .

Les valeurs de dms inférieur à 1 ou égale à 365 sont aussi considérées comme des anomalies

```{r}
data_dms <- enquete %>% 
  select(id_quest, dms, 
         categorie_corrige, mode_heb_regroupe, mode_heb_regroupe2) %>% 
  filter(!is.na(dms)) 

## Adapt grouping first based on mode_heb_regroupe and then categorie_corrige_corrige
# Analyse mode_heb_regroupe and categorie_corrige
data_dms %>% 
  count(mode_heb_regroupe, categorie_corrige)

## Adaptative grouping. if n<200 in a mode_heb_regroupe we don't separate this group.
## If n>200 we separate the group based on categorie_corrige_corrigee but categorie_corrige_corrigee that have less 
## than 50 are grouped together in "Others"

data_dms <- data_dms %>% 
  group_by(mode_heb_regroupe, categorie_corrige) %>% 
  mutate(categorie_corrige_lump = case_when(n() < 50 ~ "Other",
                                    TRUE ~ categorie_corrige)) %>% 
  group_by(mode_heb_regroupe) %>% 
  mutate(categorie_corrige_lump = case_when(n() < 200 ~ "All",
                                    TRUE ~ categorie_corrige_lump)) %>% 
  group_by(mode_heb_regroupe, categorie_corrige_lump)


data_dms %>% 
  count(mode_heb_regroupe, categorie_corrige_lump)

# Verification de quantiles
data_dms %>% 
  summarize(
    p01 = quantile(dms, 0.01),
    p10 = quantile(dms, 0.1),
    p25 = quantile(dms, 0.25),
    P75 = quantile(dms, 0.75),
    p90 = quantile(dms, 0.9),
    p99 = quantile(dms, 0.99),
    med = median(dms),
    n = n() )
```

```{r}
### detecting value <1 and == 365
data_dms %>% 
  filter(dms < 1 |
           dms == 365)

## Grouping by category
### First approach with percentile
data_dms %>% 
  filter(dms < quantile(dms, 0.01))

data_dms %>% 
  filter(dms > quantile(dms, 0.99))

### IQR approach
data_dms %>% 
  filter(dms < quantile(dms, 0.25) - 1.5 * IQR(dms) |
           dms > quantile(dms, 0.75) + 1.5 * IQR(dms))
```

## revenu (3.1.33)

Pas de groupement dans les calculs d'outlier sur les revenu. On prend juste l'ensemble des réponses.

```{r}
data_revenu <- enquete %>% 
  select(id_quest, revenu) %>% 
  filter(!is.na(revenu))

data_revenu %>% 
  summarize(
    p01 = quantile(revenu, 0.01),
    p10 = quantile(revenu, 0.1),
    p25 = quantile(revenu, 0.25),
    P75 = quantile(revenu, 0.75),
    p90 = quantile(revenu, 0.9),
    p99 = quantile(revenu, 0.99),
    med = median(revenu),
    n = n() )

```

```{r}
## First approach with percentile
data_revenu %>% 
  filter(revenu < quantile(revenu, 0.01))

data_revenu %>% 
  filter(revenu > quantile(revenu, 0.99))

## IQR approach
data_revenu %>% 
  filter(revenu < quantile(revenu, 0.25) - 1.5 * IQR(revenu) |
           revenu > quantile(revenu, 0.75) + 1.5 * IQR(revenu))
```

## depense [tour_dep_xxx] (3.1.26)

### Groupées par categorie_corrige

Pour les detections d'anomalies sur les dépenses, le groupement se fait par catégorie_corrige sauf pour les cas spécifiques TO, transport et hebergement. Attention, ces données sont vides dans mon fichier template.

```{r}
# dep_to_analyse_later <- c("tour_dep_to_jour", #2
#                           "tour_dep_heb", ## Different treatment #3
#                           "tour_dep_transp" #4
#                           )

dep_to_analyse <- c("tour_dep_alim",
                    "tour_dep_activites",
                    "tour_dep_souvenirs",
                    "tour_dep_location", 
                    "tour_dep_autres")

data_depense <- enquete %>% 
  select(id_quest, categorie_corrige,
         dplyr::all_of(dep_to_analyse)) %>% 
  tidyr::pivot_longer(starts_with("tour_dep"),
                      names_to = "depense",
                      values_to = "valeur") %>% 
  filter(!is.na(valeur)) %>% 
  group_by(depense, categorie_corrige)

data_depense %>% 
  summarize(
    p01 = quantile(valeur, 0.01),
    p10 = quantile(valeur, 0.1),
    p25 = quantile(valeur, 0.25),
    P75 = quantile(valeur, 0.75),
    p90 = quantile(valeur, 0.9),
    p99 = quantile(valeur, 0.99),
    med = median(valeur),
    n = n() )


```

```{r}
## First approach with percentile
data_depense %>% 
  filter(valeur < quantile(valeur, 0.01))

data_depense %>% 
  filter(valeur > quantile(valeur, 0.99))

## IQR approach
data_depense %>% 
  filter(valeur < quantile(valeur, 0.25) - 1.5 * IQR(valeur) |
           valeur > quantile(valeur, 0.75) + 1.5 * IQR(valeur))
```

### Groupées par mode d'hebergement

Ces dépenses sont groupées par mode d'hebergement et non par categorie_corrige: **[tour_dep_to_jour] (3.1.26.2)** et **[tour_dep_heb] (3.1.26.3)**

```{r}
data_depense <- enquete %>% 
  select(id_quest, mode_heb_regroupe,
         tour_dep_to_jour, tour_dep_heb) %>% 
  tidyr::pivot_longer(starts_with("tour_dep"),
                      names_to = "depense",
                      values_to = "valeur") %>% 
  filter(!is.na(valeur)) %>% 
  group_by(depense, mode_heb_regroupe)

data_depense %>% 
  summarize(
    p01 = quantile(valeur, 0.01),
    p10 = quantile(valeur, 0.1),
    p25 = quantile(valeur, 0.25),
    P75 = quantile(valeur, 0.75),
    p90 = quantile(valeur, 0.9),
    p99 = quantile(valeur, 0.99),
    med = median(valeur),
    n = n() )


```

```{r}

## First approach with percentile
data_depense %>% 
  filter(valeur < quantile(valeur, 0.01))

data_depense %>% 
  filter(valeur > quantile(valeur, 0.99))

## IQR approach
data_depense %>% 
  filter(valeur < quantile(valeur, 0.25) - 1.5 * IQR(valeur) |
           valeur > quantile(valeur, 0.75) + 1.5 * IQR(valeur))

```

### [tour_dep_transp] (3.1.26.4)

Le chapitre 3.1.26.4 indique plutôt des corrections et non des contrôles sur **[tour_dep_transp]** .Le groupement se fait par mode de transport. Les combinaisons sont multiples, je ne garde les catégories que s'il y a plus de 100 réponses. Les reste est classé en other.

Malheureusement mon fichier type ne contient pas de dépenses de transport.

Partie non intégrée dans le package. Methodologie à vérifier: (<https://github.com/JMPivette/evavelo/discussions/59>)

```{r}
data_dep_transp <- enquete %>% 
  select(id_quest,
         mode_transp_jour, dist_transp_jour, distance_dom_enq_reelle, 
         tour_dep_transp) %>% 
  group_by(mode_transp_jour)

data_dep_transp %>% 
  count(mode_transp_jour)

data_dep_transp %>% 
  mutate(mode_transp_lump = case_when(
    n() > 100 ~ mode_transp_jour,
    TRUE ~ "Other"
  )) %>% 
  count(mode_transp_lump)

```
